{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "\n",
    "with open(path + 'english_no_pad_sorted.pickle', 'rb') as handle:\n",
    "    english = pickle.load(handle)\n",
    "    \n",
    "with open(path + 'german_no_pad_sorted.pickle', 'rb') as handle:\n",
    "    german = pickle.load(handle)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get an average batch size of 128 Use a batch_size value of: 2652\n"
     ]
    }
   ],
   "source": [
    "def average_sentence_size(german, desired_batch_size=128):\n",
    "    summation = 0\n",
    "    for i in german['train']:\n",
    "        summation += len(i)\n",
    "    avg_tok_sent = summation/len(german['train'])\n",
    "    \n",
    "    print(\"To get an average batch size of\", desired_batch_size, \"Use a batch_size value of:\", int(desired_batch_size*avg_tok_sent))\n",
    "    \n",
    "average_sentence_size(german, desired_batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence(sent, language):\n",
    "    if language == \"german\":\n",
    "        for w in sent:\n",
    "            print(german['idx2word'][w], end=' ')\n",
    "    elif language == \"english\":\n",
    "        for w in sent:\n",
    "            print(english['idx2word'][w], end=' ')\n",
    "    else:\n",
    "        print(\"Language should be either 'german' or 'english'\")\n",
    "        \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.531226396560669\n"
     ]
    }
   ],
   "source": [
    "def get_batches(german, english, b_sz):\n",
    "    batches = [[]]\n",
    "    cur_batch = batches[-1]\n",
    "    cur_batch_len = 0\n",
    "        \n",
    "    for i in range(len(german)):\n",
    "        sent2sent = {\"source\": german[i],\n",
    "                     \"target\": english[i]}\n",
    "        \n",
    "        if cur_batch_len + len(sent2sent['source']) < b_sz:\n",
    "            cur_batch.append(sent2sent)\n",
    "            cur_batch_len += len(sent2sent['source'])\n",
    "        else:\n",
    "            batches.append([])\n",
    "            cur_batch = batches[-1]\n",
    "            cur_batch_len = 0 \n",
    "            cur_batch.append(sent2sent)\n",
    "            cur_batch_len += len(sent2sent['source'])\n",
    "\n",
    "            \n",
    "    for idx, b in enumerate(batches):\n",
    "        max_len_src = max([len(sent['source']) for sent in b])  \n",
    "        max_len_trg = max([len(sent['target']) for sent in b])\n",
    "\n",
    "        for sent in b:\n",
    "            dif_src = max_len_src - len(sent['source'])\n",
    "            dif_trg = max_len_trg - len(sent['target'])\n",
    "            \n",
    "            if dif_src > 0:\n",
    "                pad_list_src = [0 for d in range(dif_src)]\n",
    "                sent['source'].extend(pad_list_src)\n",
    "                \n",
    "            if dif_trg > 0:\n",
    "                pad_list_trg = [0 for d in range(dif_trg)]\n",
    "                sent['target'].extend(pad_list_trg)           \n",
    "            \n",
    "            sent['target'] = torch.tensor(sent['target']).to(device)\n",
    "            sent['source'] = torch.tensor(sent['source']).to(device)\n",
    "\n",
    "        \n",
    "    return batches\n",
    "t0 = time.time()\n",
    "batches = get_batches(german['train'], english['train'], 2650)\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(batches)\n",
    "print(len(batches))\n",
    "for i in range (5):\n",
    "    print(len(batches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(batch):\n",
    "    source_sent_len = len(batch[0]['source'])\n",
    "    target_sent_len = len(batch[0]['target'])\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    source = torch.empty((source_sent_len, batch_size)).to(device)    \n",
    "    target = torch.empty((target_sent_len, batch_size)).to(device)\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        source[:,i] = batch[i]['source']\n",
    "        target[:,i] = batch[i]['target']\n",
    "    \n",
    "    \n",
    "    return source, target\n",
    "\n",
    "results = []\n",
    "for i in range(100):\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    t2 = time.time()\n",
    "    for b in batches:\n",
    "        source, target = batchify(b)\n",
    "    results.append(time.time()-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.751020052433014\n"
     ]
    }
   ],
   "source": [
    "print(sum(results)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.620661735534668 3.54709529876709\n"
     ]
    }
   ],
   "source": [
    "print(min(results), max(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 110]) torch.Size([36, 110])\n"
     ]
    }
   ],
   "source": [
    "print(source.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE REASON THINGS ARE MESSED UP IS BECAUSE THE FUNCTION JUST KEEPS USING ALREADY WRITTEN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
